{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQbSJSFC/FCdtujxeHpG7x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dibend/Colab/blob/main/The_Oracle_of_New_Providence%F0%9F%94%AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The Oracle of New Providence ðŸ”®**\n",
        "\n",
        "This program uses Deep Learning to predict the price of any asset on Yahoo Finance 1 year in the future.\n",
        "\n",
        "### Disclosures\n",
        "\n",
        "#### 1. Purpose\n",
        "This code is designed to estimate the price of a user-inputted asset in one year. It is publicly available and intended for informational and educational purposes only.\n",
        "\n",
        "#### 2. Data Sources\n",
        "The code utilizes the `yfinance` library to access data from Yahoo Finance. The user acknowledges that the use of Yahoo Finance data is subject to Yahoo's terms of service, and the author of this code does not have any specific agreement with Yahoo Finance.\n",
        "\n",
        "#### 3. User Input\n",
        "Users are responsible for providing valid input in the form of a ticker symbol. The code does not validate the input, and incorrect or invalid input may lead to errors or inaccurate predictions.\n",
        "\n",
        "#### 4. Predictive Model Disclaimer\n",
        "The predictions generated by this code are based on limited historical data and a mathematical model. They are provided for informational purposes only and should not be construed as financial or investment advice. Users should consult with a qualified financial professional before making any investment decisions.\n",
        "\n",
        "#### 5. Licensing\n",
        "This code is publicly available under the GNU General Public License v3.0 (GPL-3.0). Users must comply with the terms of this license when using, modifying, or distributing the code.\n",
        "\n",
        "#### 6. Risk Factors\n",
        "Users are cautioned that the predictions generated by this code are speculative and may not accurately reflect future asset prices. Reliance on these predictions for investment decisions may result in financial loss. The author of this code is not responsible for any investment decisions or financial losses incurred by users.\n",
        "\n",
        "#### 7. Privacy\n",
        "No personal or sensitive information is collected, stored, or processed by this code.\n",
        "\n",
        "#### 8. Limitation of Liability\n",
        "The author of this code makes no warranties or representations regarding the accuracy, reliability, or completeness of the predictions or any other information provided by this code. Users use this code at their own risk, and the author shall not be liable for any direct, indirect, incidental, or consequential damages arising from its use."
      ],
      "metadata": {
        "id": "tHSVl-dKR0AH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ulLqBfrbfA3W",
        "outputId": "ad5a5a8c-0e93-4cb5-dd93-5adda0c3ad0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.27)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.25.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.3)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2022.7.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.3.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2023.7.22)\n",
            "Enter a ticker: FLUX-USD\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 6ms/step - loss: 0.4419\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0781\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0496\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0477\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0446\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0442\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0437\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0441\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0441\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0440\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0443\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0441\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0438\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0439\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0437\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0438\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0438\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0438\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0438\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0438\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0438\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0438\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0439\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0440\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0438\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0442\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0439\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0438\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0438\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0444\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0443\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0439\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0438\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0438\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0440\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0438\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0441\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0438\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0440\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0448\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0445\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0441\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0441\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0448\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0439\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0438\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0440\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0439\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0439\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0441\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0442\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0445\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0444\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0438\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0439\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0443\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0439\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0442\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0445\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0439\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0441\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0438\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0438\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0439\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0440\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0441\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0438\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0440\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0438\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0447\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0442\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0440\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0441\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0438\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0442\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0442\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0437\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0444\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0444\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0440\n",
            "12/12 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<h1>FLUX-USD Predicted Prices 1 year in the future:</h1><br />[0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.6511106  0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.6511106  0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.6511106  0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.6511106  0.65111053 0.6511106\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.6511106  0.65111053 0.65111053 0.6511106  0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.6511106\n 0.65111053 0.6511106  0.6511106  0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.6511106  0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.6511106  0.65111053 0.6511106\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.6511106  0.6511106\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.6511106  0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.6511106  0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053\n 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053 0.65111053]<br /><br /><h1>FLUX-USD Average Predicted Price 1 Year in the Future:<br />&dollar;0.65111065<br /><br />FLUX-USD Current Price:<br />&dollar;0.41008809208869934<br /><br />FLUX-USD Percent Change from Current Price to Average Predicted Price 1 Year in the Future:<br /><font color=\"green\">58.773361545951886% increase</font></h1>"
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#Install yfinance dependency for accessing Yahoo Finance data\n",
        "!pip install yfinance\n",
        "\n",
        "#Import yfinance, which allows us to access stock market data, and tensorflow, which allows us to create and use machine learning models\n",
        "import yfinance as yf\n",
        "import tensorflow as tf\n",
        "\n",
        "#Import numpy, which allows us to perform mathematical operations on arrays, and IPython's display library, which allows us to display formatted data\n",
        "import numpy as np\n",
        "from IPython.display import Markdown as md\n",
        "\n",
        "#Ask the user to input a ticker\n",
        "ticker = input('Enter a ticker: ')\n",
        "\n",
        "#Download a year's worth of data for the stock the user entered\n",
        "data = yf.download(ticker, period='1y')\n",
        "\n",
        "#Normalize the data using TensorFlow's Keras utility\n",
        "matrix = tf.keras.utils.normalize(data.values)\n",
        "\n",
        "#Create a sequential machine learning model using TensorFlow's Keras library\n",
        "model = tf.keras.models.Sequential()\n",
        "#Add a densely connected layer with 128 neurons and ReLU activation\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(matrix.shape[1],)))\n",
        "#Add a densely connected layer with 64 neurons and ReLU activation\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "#Add a densely connected layer with 1 neuron\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "#Compile the model using the Adam optimizer and mean squared error loss\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "#Train the model using the normalized data and the stock prices\n",
        "model.fit(matrix, data['Close'], epochs=100)\n",
        "\n",
        "#Use the trained model to predict prices for the stock\n",
        "predicted_prices = model.predict(matrix)\n",
        "#Flatten the predicted prices array\n",
        "predicted_prices = np.array(predicted_prices).flatten()\n",
        "\n",
        "#Calculate the average predicted price\n",
        "mean_predicted_price = np.mean(predicted_prices)\n",
        "\n",
        "#Get the current price of the stock\n",
        "current_price = data['Close'][-1]\n",
        "#Calculate the change from the current price to the average predicted price\n",
        "change = (mean_predicted_price - current_price) / current_price\n",
        "#Calculate the percent change\n",
        "percent_change = change * 100\n",
        "\n",
        "#Set variables to control the color and wording of the output\n",
        "color = 'red'\n",
        "increase_decrease = 'decrease'\n",
        "\n",
        "#If the percent change is positive, set the color and wording variables to green and increase, respectively\n",
        "if percent_change >= 0:\n",
        "  increase_decrease = 'increase'\n",
        "  color = 'green'\n",
        "\n",
        "#Display the predicted and current prices, as well as the change in a formatted manner\n",
        "md('<h1>' + ticker + ' Predicted Prices 1 year in the future:</h1><br />' + str(predicted_prices) +\n",
        "  '<br /><br /><h1>' + ticker + ' Average Predicted Price 1 Year in the Future:<br />&dollar;' + str(mean_predicted_price) +\n",
        "  '<br /><br />' + ticker + ' Current Price:<br />&dollar;' + str(current_price) +\n",
        "  '<br /><br />' + ticker + ' Percent Change from Current Price to Average Predicted Price 1 Year in the Future:<br /><font color=\"' + color + '\">' +\n",
        "  str(percent_change) + '% ' + increase_decrease + '</font></h1>')"
      ]
    }
  ]
}